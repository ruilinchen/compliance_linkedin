{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/rchen/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/rchen/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def text_preprocess(a_string):\n",
    "    \"\"\"\n",
    "    clean the text: remove punctuations; lemmatization\n",
    "    \"\"\"\n",
    "    a_string = a_string[:int(len(a_string) * 0.5)]\n",
    "    main_words = re.sub('[^a-zA-Z]', ' ', a_string)  # Retain only alphabets\n",
    "    main_words = (main_words.lower()).split()\n",
    "    main_words = [w for w in main_words if not w in set(stopwords.words('english'))]  # Remove stopwords\n",
    "    main_words = [lem.lemmatize(w) for w in main_words if len(w) > 1]  # Group different forms of the same word\n",
    "    main_words = ' '.join(main_words)\n",
    "    return main_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Preprocessing\n",
    "* clean the job_description column\n",
    "* combine individual files into one"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "RAW_TEXT_COLNAME = 'lnks_job_description'\n",
    "CLEANED_TEXT_COLNAME = 'clean_job_description'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 98.31it/s] \n",
      "  0%|          | 9/2195 [00:03<13:18,  2.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m         filtered_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([filtered_df, job_df])\n\u001B[1;32m     12\u001B[0m tqdm\u001B[38;5;241m.\u001B[39mpandas()\n\u001B[0;32m---> 13\u001B[0m filtered_df[CLEANED_TEXT_COLNAME] \u001B[38;5;241m=\u001B[39m \u001B[43mfiltered_df\u001B[49m\u001B[43m[\u001B[49m\u001B[43mRAW_TEXT_COLNAME\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprogress_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_preprocess\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m filtered_df\u001B[38;5;241m.\u001B[39mto_csv(labeled_filename, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/tqdm/std.py:814\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001B[0;34m(df, func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    811\u001B[0m \u001B[38;5;66;03m# Apply the provided function (in **kwargs)\u001B[39;00m\n\u001B[1;32m    812\u001B[0m \u001B[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001B[39;00m\n\u001B[1;32m    813\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 814\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_function\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    816\u001B[0m     t\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/pandas/core/series.py:4774\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4664\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4665\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4666\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4669\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4670\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4671\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4672\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4673\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4772\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4773\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4774\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/pandas/core/apply.py:1100\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1097\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m-> 1100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/pandas/core/apply.py:1151\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1150\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m-> 1151\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1159\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2919\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/tqdm/std.py:809\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    804\u001B[0m     \u001B[38;5;66;03m# update tbar correctly\u001B[39;00m\n\u001B[1;32m    805\u001B[0m     \u001B[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001B[39;00m\n\u001B[1;32m    806\u001B[0m     \u001B[38;5;66;03m# on the first column/row to decide whether it can\u001B[39;00m\n\u001B[1;32m    807\u001B[0m     \u001B[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001B[39;00m\n\u001B[1;32m    808\u001B[0m     t\u001B[38;5;241m.\u001B[39mupdate(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mn \u001B[38;5;241m<\u001B[39m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 809\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36mtext_preprocess\u001B[0;34m(a_string)\u001B[0m\n\u001B[1;32m     17\u001B[0m main_words \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[^a-zA-Z]\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, a_string)  \u001B[38;5;66;03m# Retain only alphabets\u001B[39;00m\n\u001B[1;32m     18\u001B[0m main_words \u001B[38;5;241m=\u001B[39m (main_words\u001B[38;5;241m.\u001B[39mlower())\u001B[38;5;241m.\u001B[39msplit()\n\u001B[0;32m---> 19\u001B[0m main_words \u001B[38;5;241m=\u001B[39m [w \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m main_words \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m(stopwords\u001B[38;5;241m.\u001B[39mwords(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m'\u001B[39m))]  \u001B[38;5;66;03m# Remove stopwords\u001B[39;00m\n\u001B[1;32m     20\u001B[0m main_words \u001B[38;5;241m=\u001B[39m [lem\u001B[38;5;241m.\u001B[39mlemmatize(w) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m main_words \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(w) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# Group different forms of the same word\u001B[39;00m\n\u001B[1;32m     21\u001B[0m main_words \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(main_words)\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     17\u001B[0m main_words \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[^a-zA-Z]\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, a_string)  \u001B[38;5;66;03m# Retain only alphabets\u001B[39;00m\n\u001B[1;32m     18\u001B[0m main_words \u001B[38;5;241m=\u001B[39m (main_words\u001B[38;5;241m.\u001B[39mlower())\u001B[38;5;241m.\u001B[39msplit()\n\u001B[0;32m---> 19\u001B[0m main_words \u001B[38;5;241m=\u001B[39m [w \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m main_words \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m(\u001B[43mstopwords\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwords\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43menglish\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)]  \u001B[38;5;66;03m# Remove stopwords\u001B[39;00m\n\u001B[1;32m     20\u001B[0m main_words \u001B[38;5;241m=\u001B[39m [lem\u001B[38;5;241m.\u001B[39mlemmatize(w) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m main_words \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(w) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# Group different forms of the same word\u001B[39;00m\n\u001B[1;32m     21\u001B[0m main_words \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(main_words)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/nltk/corpus/reader/wordlist.py:21\u001B[0m, in \u001B[0;36mWordListCorpusReader.words\u001B[0;34m(self, fileids, ignore_lines_startswith)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwords\u001B[39m(\u001B[38;5;28mself\u001B[39m, fileids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, ignore_lines_startswith\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m     20\u001B[0m         line\n\u001B[0;32m---> 21\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m line_tokenize(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfileids\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line\u001B[38;5;241m.\u001B[39mstartswith(ignore_lines_startswith)\n\u001B[1;32m     23\u001B[0m     ]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/nltk/corpus/reader/api.py:218\u001B[0m, in \u001B[0;36mCorpusReader.raw\u001B[0;34m(self, fileids)\u001B[0m\n\u001B[1;32m    216\u001B[0m contents \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fileids:\n\u001B[0;32m--> 218\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fp:\n\u001B[1;32m    219\u001B[0m         contents\u001B[38;5;241m.\u001B[39mappend(fp\u001B[38;5;241m.\u001B[39mread())\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concat(contents)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/nltk/corpus/reader/api.py:231\u001B[0m, in \u001B[0;36mCorpusReader.open\u001B[0;34m(self, file)\u001B[0m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;124;03mReturn an open stream that can be used to read the given file.\u001B[39;00m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;124;03mIf the file's encoding is not None, then the stream will\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;124;03m:param file: The file identifier of the file to read.\u001B[39;00m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    230\u001B[0m encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoding(file)\n\u001B[0;32m--> 231\u001B[0m stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_root\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stream\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/compsoc/lib/python3.8/site-packages/nltk/data.py:324\u001B[0m, in \u001B[0;36mFileSystemPathPointer.open\u001B[0;34m(self, encoding)\u001B[0m\n\u001B[1;32m    323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 324\u001B[0m     stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m encoding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    326\u001B[0m         stream \u001B[38;5;241m=\u001B[39m SeekableUnicodeStreamReader(stream, encoding)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "labeled_filename = 'labelled_data/all_labelled_jobs.csv' # outout filename\n",
    "labeled_files = [os.path.join('labelled_data', item) for item in os.listdir('labelled_data') if '.csv' in item] # individual files to be processed\n",
    "\n",
    "filtered_df = None\n",
    "for file in tqdm(labeled_files, total=len(labeled_files)):\n",
    "    job_df = pd.read_csv(file)  # required columns: lnks_job_title, lnks_job_description\n",
    "    if filtered_df is None:\n",
    "        filtered_df = job_df\n",
    "    else:\n",
    "        filtered_df = pd.concat([filtered_df, job_df])\n",
    "\n",
    "tqdm.pandas()\n",
    "filtered_df[CLEANED_TEXT_COLNAME] = filtered_df[RAW_TEXT_COLNAME].progress_apply(text_preprocess)\n",
    "filtered_df.to_csv(labeled_filename, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Need to run this for both the labeled data and the raw unlabeled data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}